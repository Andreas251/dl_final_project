{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial from https://towardsdatascience.com/how-to-fine-tune-gpt-2-for-text-generation-ae2ea53bc272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://www.kaggle.com/datasets/neisse/scrapped-lyrics-from-6-genres?resource=download&select=artists-data.csv\n",
    "# Prepare data (Not needed for kanye lyrics)\n",
    "lyrics = pd.read_csv('data/lyrics-data.csv')\n",
    "lyrics = lyrics[lyrics['language']=='en']\n",
    "\n",
    "# Only keep popular artists, with genre Rock/Pop and popularity high enough\n",
    "artists = pd.read_csv('data/artists-data.csv')\n",
    "artists = artists[(artists['Genres'].isin(['Rock'])) & (artists['Popularity']>5)]\n",
    "\n",
    "# print(artists)\n",
    "df = lyrics.merge(artists[['Artist', 'Genres', 'Link']], left_on='ALink', right_on='Link', how='inner')\n",
    "df = df.drop(columns=['ALink','SLink','language','Link'])\n",
    "\n",
    "# Drop the songs with lyrics too long (after more than 1024 tokens, does not work)\n",
    "df = df[df['Lyric'].apply(lambda x: len(x.split(' ')) < 350)]\n",
    "\n",
    "# Create a very small test set to compare generated text with the reality\n",
    "test_set = df.sample(n = 200)\n",
    "df = df.loc[~df.index.isin(test_set.index)]\n",
    "\n",
    "# Reset the indexes\n",
    "test_set = test_set.reset_index()\n",
    "df = df.reset_index()\n",
    "\n",
    "# For the test set only, keep last 20 words in a new column, then remove them from original column\n",
    "test_set['True_end_lyrics'] = test_set['Lyric'].str.split().str[-20:].apply(' '.join)\n",
    "test_set['Lyric'] = test_set['Lyric'].str.split().str[:-20].apply(' '.join)\n",
    "\n",
    "\n",
    "# SName, Lyric, Artist, Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize lyrics\n",
    "\n",
    "class SongLyrics(Dataset):  \n",
    "    def __init__(self, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n",
    "\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
    "        self.lyrics = []\n",
    "\n",
    "        for row in df['Lyric']:\n",
    "          self.lyrics.append(torch.tensor(\n",
    "                self.tokenizer.encode(f\"<|{control_code}|>{row[:max_length]}<|endoftext|>\")\n",
    "            ))               \n",
    "        if truncate:\n",
    "            self.lyrics = self.lyrics[:20000]\n",
    "        self.lyrics_count = len(self.lyrics)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.lyrics_count\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.lyrics[item]\n",
    "    \n",
    "dataset = SongLyrics(df['Lyric'], truncate=True, gpt2_type=\"gpt2\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "#Accumulated batch size (since GPT2 is so big)\n",
    "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
    "    if packed_tensor is None:\n",
    "        return new_tensor, True, None\n",
    "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
    "        return packed_tensor, False, new_tensor\n",
    "    else:\n",
    "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
    "        return packed_tensor, True, None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05c4c729e88282d67eca00fe45a6137539b4020d6694da1fe52091cd432aba7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
